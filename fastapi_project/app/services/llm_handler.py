# app/services/llm_handler.py
import time
import traceback
from langchain_community.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from app.schemas.resume_extract import ResumeInfo

# 1. ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜
response_schemas = [
    ResponseSchema(name="certification_count", description="ìê²©ì¦ ë˜ëŠ” ì¸ì¦ ê°œìˆ˜ (ì •ìˆ˜)"),
    ResponseSchema(name="project_count", description="í”„ë¡œì íŠ¸ ë˜ëŠ” êµ¬í˜„ ê²½í—˜ ê°œìˆ˜ (ì •ìˆ˜)"),
    ResponseSchema(name="major_type", description="ì „ê³µì´ ì»´í“¨í„°/ì†Œí”„íŠ¸ì›¨ì–´/AI/IT ê´€ë ¨ì´ë©´ 'MAJOR', ì•„ë‹ˆë©´ 'NON_MAJOR'"),
    ResponseSchema(name="company_name", description="ì‹¤ì œ ê·¼ë¬´ ì´ë ¥ì´ ëª…í™•íˆ ê¸°ì¬ëœ ê°€ì¥ ìµœê·¼ íšŒì‚¬ëª… (ì—†ìœ¼ë©´ null)"),
    ResponseSchema(name="work_period", description="ì‹¤ì œ ê·¼ë¬´ ì´ë ¥ì´ ëª…í™•íˆ ê¸°ì¬ëœ ê°€ì¥ ìµœê·¼ íšŒì‚¬ì—ì„œì˜ ê·¼ë¬´ ê¸°ê°„ì„ ì›” ë‹¨ìœ„ ì •ìˆ˜ë¡œ ê³„ì‚° (ì—†ìœ¼ë©´ 0)"),
    ResponseSchema(name="position", description="ì‹¤ì œ ê·¼ë¬´ ì´ë ¥ì´ ëª…í™•íˆ ê¸°ì¬ëœ ê²½ë ¥ ì¤‘ ê°€ì¥ ìµœê·¼ íšŒì‚¬ì—ì„œì˜ ì§ë¬´ëª… (ì—†ìœ¼ë©´ null)"),
    ResponseSchema(name="additional_experiences", description="ìê²©ì¦/í”„ë¡œì íŠ¸/ê²½ë ¥ ì´ì™¸ì˜ ê¸°íƒ€ ëŒ€ì™¸ í™œë™ ì •ë¦¬ (ì—†ìœ¼ë©´ null)")
]

parser = StructuredOutputParser.from_response_schemas(response_schemas)

# 2. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
prompt = ChatPromptTemplate.from_messages([
    ("system", """
ë„ˆëŠ” ì‚¬ìš©ìì˜ ì´ë ¥ì„œë¥¼ ë¶„ì„í•´ **ì •í™•íˆ í•˜ë‚˜ì˜ JSON ê°ì²´**ë§Œ ì¶œë ¥í•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ ì•„ë˜ ê¸°ì¤€ì„ ì§€ì¼œì¤˜.

ğŸ“Œ ì¶œë ¥ í˜•ì‹ì€ ì•„ë˜ 7ê°œ í•­ëª©ì˜ **ë‹¨ì¼ ê°’**ì´ë©°, ì ˆëŒ€ ë¦¬ìŠ¤íŠ¸ ê¸ˆì§€:

- certification_count: ìê²©ì¦ ê°œìˆ˜ (ì •ìˆ˜)
- project_count: í”„ë¡œì íŠ¸ ë˜ëŠ” êµ¬í˜„ ê²½í—˜ ê°œìˆ˜ (ì •ìˆ˜)
- major_type: ì»´í“¨í„°/AI/IT ê³„ì—´ ì „ê³µì´ë©´ "MAJOR", ì•„ë‹ˆë©´ "NON_MAJOR"
- company_name: ê·¼ë¬´/ì¸í„´/ì¬ì§/ì†Œì† ë“±ì˜ í‘œí˜„ì´ ëª…í™•íˆ ì–¸ê¸‰ëœ **ìµœê·¼ íšŒì‚¬ëª… 1ê°œ** (ì—†ìœ¼ë©´ null)
- work_period: ìœ„ íšŒì‚¬ì˜ ìµœê·¼ ì´ë ¥ ê·¼ë¬´ê¸°ê°„ ì´ ê°œì›” ìˆ˜ (ì˜ˆ: 2023.01~2024.01 â†’ 13)
- position: ìœ„ íšŒì‚¬ì—ì„œ ë§¡ì€ ì§ë¬´ëª… (ì—†ìœ¼ë©´ null)
- additional_experiences: ìê²©ì¦/í”„ë¡œì íŠ¸/ê·¼ë¬´ ì™¸ ê²½í—˜ (ë™ì•„ë¦¬, ìˆ˜ìƒ, ëŒ€ì™¸í™œë™ ë“±). ì—†ìœ¼ë©´ null

â—ï¸ì£¼ì˜ì‚¬í•­ (ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ):

- ë‹¨ìˆœ ê¸°ì—… ì–¸ê¸‰/í˜‘ì—…/ìˆ˜ìƒ/ì„¸ë¯¸ë‚˜ëŠ” ì ˆëŒ€ ê·¼ë¬´ë¡œ íŒë‹¨í•˜ì§€ ë§ˆì„¸ìš”.
- ê·¼ë¬´/ì¸í„´ìœ¼ë¡œ í™•ì‹¤íˆ ì–¸ê¸‰ëœ ê²½ìš°ë§Œ company_name, work_period, positionì„ ì¶”ì¶œí•˜ì„¸ìš”.
- certification_countì—ëŠ” 'ìê²©ì¦', 'ê¸°ì‚¬', 'SQLD', 'ì»´í™œ', 'TOEIC', 'ìš´ì „ë©´í—ˆ' ë“±ê³¼ ì ìˆ˜/ë“±ê¸‰ì´ í•¨ê»˜ ìˆëŠ” í•­ëª©ë§Œ í¬í•¨í•˜ì„¸ìš”.
- additional_experiencesì—ëŠ” ë°˜ë“œì‹œ ì„±ê³¼ ê¸°ë°˜ì˜ ì™¸ë¶€ í™œë™ë§Œ í¬í•¨í•˜ê³ , ìê²©ì¦/ê·¼ë¬´/í”„ë¡œì íŠ¸ ë‚´ìš©ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

ğŸ“… ê¸°ì¤€ì¼ì€ 2025ë…„. "í˜„ì¬"ëŠ” 2025ë…„ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
"""),
    ("user", "{text}"),
    ("system", "{format_instructions}")
])

# 3. ëª¨ë¸ ì •ì˜
llm = ChatOpenAI(
    model="/mnt/ssd/aya-expanse-8b",
    openai_api_base="http://localhost:8001/v1",
    openai_api_key="NULL",
    temperature=0.3,
    max_tokens=512
)

# 4. ì•ˆì „í•œ ì •ìˆ˜ íŒŒì‹± í•¨ìˆ˜
def safe_int(val):
    try:
        return int(val)
    except:
        return 0

# 5. LLM ì¶”ë¡  í•¨ìˆ˜
async def extract_info_from_resume(resume_text: str) -> dict:
    fallback_result = {
        "certification_count": 0,
        "project_count": 0,
        "major_type": "NON_MAJOR",
        "company_name": None,
        "work_period": 0,
        "position": None,
        "additional_experiences": None
    }

    MAX_RETRY = 2
    for attempt in range(MAX_RETRY):
        try:
            format_instructions = parser.get_format_instructions()
            filled_prompt = prompt.format_messages(
                text=resume_text.strip()[:6000],
                format_instructions=format_instructions
            )

            start = time.time()
            response = await llm.ainvoke(filled_prompt)
            end = time.time()

            content = response.content
            print(f"\nâ±ï¸ ì‘ë‹µ ì‹œê°„: {end - start:.2f}ì´ˆ")
            print("ğŸ§  LLM ì‘ë‹µ ì›ë¬¸:\n", content)

            parsed_dict = parser.parse(content)

            # position í•„ë“œ ì •ë¦¬
            position_raw = parsed_dict.get("position")
            position = position_raw[0] if isinstance(position_raw, list) and position_raw else position_raw or None

            # additional_experiences í•„ë“œ ì •ë¦¬
            add_exp = parsed_dict.get("additional_experiences")
            if isinstance(add_exp, list):
                add_exp = "\n".join(add_exp)
            elif not isinstance(add_exp, str):
                add_exp = None

            return ResumeInfo(
                certification_count=safe_int(parsed_dict.get("certification_count")),
                project_count=safe_int(parsed_dict.get("project_count")),
                major_type=parsed_dict.get("major_type", "NON_MAJOR"),
                company_name=parsed_dict.get("company_name") or None,
                work_period=safe_int(parsed_dict.get("work_period")),
                position=position,
                additional_experiences=add_exp
            ).dict()

        except Exception as e:
            print(f"âš ï¸ LLM ì¶”ë¡  ì‹œë„ {attempt + 1} ì‹¤íŒ¨:", e)
            traceback.print_exc()
            if attempt == MAX_RETRY - 1:
                print("âš ï¸ LLM ì¶”ë¡  2íšŒ ì‹¤íŒ¨. fallback ë°˜í™˜")
                return fallback_result